{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLAS.get_num_threads() = 1\n",
      "  0.211251 seconds (2 allocations: 30.518 MiB)\n",
      "BLAS.get_num_threads() = 4\n",
      "  0.124283 seconds (2 allocations: 30.518 MiB, 1.41% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000×2000 Matrix{Float64}:\n",
       " 485.913  498.432  484.765  479.025  …  499.488  481.598  491.073  487.787\n",
       " 498.413  502.77   488.947  489.869     508.926  491.233  502.087  499.032\n",
       " 494.15   501.504  486.227  492.665     497.294  487.428  495.098  499.047\n",
       " 500.173  506.289  495.724  491.75      498.706  482.809  497.076  503.163\n",
       " 504.567  513.291  504.303  500.12      506.772  494.67   506.264  508.77\n",
       " 498.99   495.169  490.198  492.764  …  505.851  479.577  499.977  503.583\n",
       " 482.553  487.092  483.417  482.972     490.316  478.439  490.105  493.793\n",
       " 499.127  506.137  498.5    489.557     506.614  495.374  499.704  504.379\n",
       " 495.89   505.844  489.836  489.214     507.048  486.017  502.481  504.705\n",
       " 501.3    495.071  499.276  494.009     502.404  489.003  500.824  501.011\n",
       " 487.408  504.001  497.758  495.156  …  501.588  484.862  501.403  499.836\n",
       " 482.87   496.119  484.207  484.988     494.966  484.551  488.235  497.132\n",
       " 490.514  494.055  487.844  481.352     495.964  479.838  489.168  495.748\n",
       "   ⋮                                 ⋱                             \n",
       " 504.338  504.74   502.68   495.378     507.17   490.707  502.3    514.667\n",
       " 514.425  512.672  508.422  506.872     516.051  502.568  511.01   513.838\n",
       " 484.143  490.949  474.196  483.466  …  495.199  482.462  492.926  493.962\n",
       " 503.474  513.495  499.852  504.882     507.274  491.188  512.002  511.594\n",
       " 491.81   504.284  496.024  496.988     506.413  490.98   505.253  499.295\n",
       " 497.063  498.566  501.215  491.57      504.045  483.243  499.29   499.493\n",
       " 507.728  516.362  505.83   508.872     522.571  496.139  513.396  515.722\n",
       " 507.778  512.508  505.093  500.01   …  511.744  490.139  511.049  507.547\n",
       " 497.128  507.747  504.956  500.665     506.416  489.332  506.175  507.864\n",
       " 493.992  495.706  492.386  496.646     494.957  481.531  505.099  491.414\n",
       " 504.088  508.8    501.99   494.062     508.616  493.691  510.827  504.297\n",
       " 503.3    501.399  503.935  492.909     511.017  491.226  509.965  503.478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "A = rand(2000, 2000);\n",
    "B = rand(2000, 2000);\n",
    "\n",
    "# Precompile the matrix multiplication\n",
    "A*B;\n",
    "\n",
    "# Single thread\n",
    "begin\n",
    "    BLAS.set_num_threads(1)\n",
    "    @show BLAS.get_num_threads()\n",
    "    @time A*B\n",
    "end\n",
    "\n",
    "# All threads on the machine\n",
    "begin\n",
    "    BLAS.set_num_threads(Sys.CPU_THREADS)\n",
    "    @show BLAS.get_num_threads()\n",
    "    @time A*B\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Base.Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three main ways of approaching multithreading:\n",
    "\n",
    "1. Using `@threads` to parallelize a for loop to run in multiple threads.\n",
    "2. Using `@spawn` and `@sync` to spawn tasks in threads and synchronize them at the end of the block.\n",
    "3. Using `@spawn` and `fetch` to spawn tasks and fetch their return values once they are complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `@threads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zeros(Int, 2*nthreads())\n",
    "@threads for i in eachindex(a)\n",
    "    a[i] = threadid()\n",
    "end\n",
    "println(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `@spawn` and `@sync`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function task(b, chunk)\n",
    "     for i in chunk\n",
    "         b[i] = threadid()\n",
    "     end\n",
    "end\n",
    "\n",
    "# Using @sync and @spawn macros (also dynamic scheduling)\n",
    "b = zeros(Int, 2 * nthreads())\n",
    "chunks = Iterators.partition(eachindex(b), length(b) ÷ nthreads())\n",
    "@sync for chunk in chunks\n",
    "    @spawn task(b, chunk)\n",
    "end\n",
    "println(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of `@spawn` and `fetch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using @spawn and fetch\n",
    "t = [@spawn threadid() for _ in 1:2*nthreads()]\n",
    "c = fetch.(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sqrt_array(A)\n",
    "  B = similar(A)\n",
    "  for i in eachindex(A)\n",
    "      @inbounds B[i] = sqrt(A[i])\n",
    "  end\n",
    "  B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function threaded_sqrt_array(A)\n",
    "  B = similar(A)\n",
    "  @threads for i in eachindex(A)\n",
    "      @inbounds B[i] = sqrt(A[i])\n",
    "  end\n",
    "  B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sqrt_array!(A, B, chunk)\n",
    "  for i in chunk\n",
    "      @inbounds B[i] = sqrt(A[i])\n",
    "  end\n",
    "end\n",
    "\n",
    "function threaded_sqrt_array2(A)\n",
    "  B = similar(A)\n",
    "  chunks = Iterators.partition(eachindex(A), length(A) ÷ nthreads())\n",
    "  @sync for chunk in chunks\n",
    "      @spawn sqrt_array!(A, B, chunk)\n",
    "  end\n",
    "  B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = rand(1000, 1000)\n",
    "\n",
    "using BenchmarkTools\n",
    "\n",
    "@btime sqrt_array(A);\n",
    "@btime threaded_sqrt_array(A);\n",
    "@btime threaded_sqrt_array2(A);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output from one attempt with `-t 3`\n",
    "\n",
    "```\n",
    "julia> @btime sqrt_array(A);\n",
    "  665.875 μs (2 allocations: 7.63 MiB)\n",
    "\n",
    "julia> @btime threaded_sqrt_array(A);\n",
    "  263.750 μs (20 allocations: 7.63 MiB)\n",
    "\n",
    "julia> @btime threaded_sqrt_array2(A);\n",
    "  418.916 μs (32 allocations: 7.63 MiB)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@thread` is fast, powerful and easy to implement but it can only be used if each operation is **independent of each other**. Otherwise, race conditions might lead to wrong results. The following is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slow but correct\n",
    "\n",
    "function sqrt_sum(A)\n",
    "  s = zero(eltype(A))\n",
    "  for i in eachindex(A)\n",
    "      @inbounds s += sqrt(A[i])\n",
    "  end\n",
    "  return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast but incorrect. Returns the sum only for a subset of the whole input array.\n",
    "\n",
    "function threaded_sqrt_sum(A)\n",
    "  s = zero(eltype(A))\n",
    "  @threads for i in eachindex(A)\n",
    "      @inbounds s += sqrt(A[i])\n",
    "  end\n",
    "  return s\n",
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast and correct but after refactoring\n",
    "\n",
    "function sqrt_sum(A, chunk)\n",
    "  s = zero(eltype(A))\n",
    "  for i in chunk\n",
    "      @inbounds s += sqrt(A[i])\n",
    "  end\n",
    "  return s\n",
    "end\n",
    "\n",
    "function threaded_sqrt_sum_workaround(A)\n",
    "  chunks = Iterators.partition(eachindex(A), length(A) ÷ nthreads())\n",
    "  tasks = map(chunks) do chunk\n",
    "      @spawn sqrt_sum(A, chunk)\n",
    "  end\n",
    "  s = mapreduce(fetch, +, tasks; init=zero(eltype(A)))\n",
    "  return s\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
